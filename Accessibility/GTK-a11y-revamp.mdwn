# Revamping the GTK accessibility stack?

### URLs

Discussion sort-of started here (but not only)

[[https://gitlab.gnome.org/GNOME/gtk/issues/1739]]

Input questions are detailed on [[Accessibility/Input]]

### Coherency ###

We most probably want to keep coherent with other interfaces:

* Microsoft's UIA/IA2/MSAA
* OS X's NSAccessibility

The technical IPC mechanism details and the IPC interface details vary, but the ground principle is the same:

* The screen reader uses an IPC to get information from application's widgets.
* The toolkit used by the application implements the server hooks.
* The toolkit sends notifications for events that are useful to screen readers (e.g. text change)
* Some IPCs do have effect/actions in the application

### Strong issues ###

* AT-SPI allows any application to access information, act on the application etc.
* key snooping makes *all* keypresses go through the screen reader, thus making the whole desktop slower
* key snooping doesn't work on wayland, making screen readers very difficult to use, [[https://gitlab.gnome.org/GNOME/mutter/issues/9]]
* Stealing key events from gtk is considered wrong, it should go through other means [[https://gitlab.gnome.org/GNOME/gtk/issues/1739#note_458183]]

### Issues ###

* The ATK key event seems too raw and clenched on X11 specifics [[https://bugzilla.gnome.org/show_bug.cgi?id=649559#c3]]
* ATK itself is cumbersome
  * at-spi2-core + at-spi2-atk + atk + gtk
  * while gtk could directly talk at-spi (like Qt does).

### Usage needs

* Getting audio feedback for the currently-focused widget: when going from one to the other, when the current widget changes, when a notification widget notifies of something.
* Getting audio feedback of what is being typed, thus the translated key, not only the keycode.
* Screen reader driven through shortcuts, to e.g. spell a letter, spell a word, read the current selection, speak the current logical position (window, panel, group, widget), change feedback verbosity, etc.
* Simulate mouse clicks (for when there is no keyboard shortcut defined)

### technical needs

* key press events with translated key, not only the keycode
* keyboard shortcut 
* Mouse click simulation

### Ideas for solutions

* Checking authorization before allowing connection to AT-SPI

* Separating out key press notification from keyboard shortcuts:
  * key press notification can be asynchronous, thus not slowing desktop down
  * only keyboard shortcut would have to go through the screen reader

* Implementing keyboard shortcuts for accessibility within the toolkit itself
  * But the screen reader has its own state (e.g. feedback verbosity level)

* Implement accessibility support (such as "read current line") within the toolkit itself
  * There are a *lot* of such things that would need to be implemented to make working with speech feedback workable.
  * That makes integration with other screen reader behavior extremely difficult
    * We need to have it interrupted by e.g. desktop notifications, focus change, etc.
  * and it's then not toolkit agnostic

* key press/shortcut transmission
  * through XInput? Not available on Wayland
  * through AT-SPI or another protocol? We want authorization to avoid arbitrary key snooping, if we add authorization over the whole AT-SPI that should be fine
  * A bridge for dogtail was implemented on [[https://gitlab.gnome.org/ofourdan/gnome-ponytail-daemon]] but this is more of a hack
  * A macro daemon is currently in development on [[https://gitlab.freedesktop.org/whot/macrod/]]
  * Wayland security module [[https://lists.freedesktop.org/archives/wayland-devel/2015-March/020474.html]]

* key press feedback
  * Key presses
  * But also input method expansions
