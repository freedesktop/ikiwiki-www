# Use cases

### Users who can only use a keyboard

Need keyboard shortcuts for all actions in applications.

Need to be able to drive the pointer for positioning actions (-> MouseKeys)

### Users who can only use a joystick

Need to be able to drive the pointer -> [[support in libinput?|https://gitlab.freedesktop.org/libinput/libinput/issues/255]]

### Users who can only drive the pointer, or just use a button

Need to use a virtual keyboard.

### Users who can only move an eye

Need to use eye-tracking, e.g. with http://viacam.org , which needs to drive the pointer.

It also needs to detect when the user is using the traditional mouse, to disable the tracker when somebody else is assisting the user.

### Users who can not afford any of these, but can speak

Need to use speech recognition.

Triggered actions should be not only keypresses, but also high-level actions, to avoid having to know and spell the keypresses to use to achieve the action, i.e. "copy", "paste", not "control-c", "control-v".

The actions can also be selecting e.g. an icon by its name.

### Selecting a region

shouldn't require using a mouse. Mark & point method needs to be available.

### Half-keyboard

For people with one hand, using a toggle to "mirror" the keyboard layout. Some implementations use xkb: 
[[http://blog.xkcd.com/2007/08/14/mirrorboard-a-one-handed-keyboard-layout-for-the-lazy/]] , others use extensions: [[http://kieranbingham.co.uk/implementing-xhk/]] , [[https://github.com/kbingham/xhk]]

### AccessX

Done in Xorg, done in mutter

* [[StickyKeys|https://en.wikipedia.org/wiki/Sticky_keys]]: modifiers are sticky so the user does not have to be able to press several keys at the same time
* [[MouseKeys|https://en.wikipedia.org/wiki/Mouse_keys]]: mouse can be driven from the keyboard
* [[SlowKeys|https://en.wikipedia.org/wiki/Slow_keys]]: only keys that are held for a long time produce a key event.
* [[RepeatKeys|https://docs.oracle.com/cd/E19620-01/802-7634/accessx-25/index.html]]: the repeat delay can be set to a very long time.
* [[ToggleKeys|https://en.wikipedia.org/wiki/ToggleKeys]]: makes an audible feedback when a toggle (capslock, numlock) is enabled (beep once) or disabled (beep twice)
* [[BounceKeys|https://en.wikipedia.org/wiki/Bounce_keys]]: ignores rapid, repeated key events for the same key

### Navigation shortcuts

The user uses shortcuts to tell the screen reader specific actions (read the current line, the current character, spell the current word, detail the attributes of the text, get the content of the status bar, change feedback verbosity level, navigate the interface with global view, etc.)

To avoid interfering with usual shortcuts in some situations, some of these are done with a "screen reader" key that needs to be pressed like a modifier. Typically, insert and capslock are used. For instance, one types insert-v to change the verbosity level. Double-typing that "screen reader" key however should allow to achieve the original behavior.

### key typing feedback

Users needs to have audio feedback of what they are typing, i.e. not the physical key, but the label of the key that was pressed. 

In the case of the Compose key, the resulting output should be spoken.

In the case of input methods, the resulting output should be spoken as well.

### Mouse review

User needs feedback on what is under the pointer, to be sure what sâ‹…he clicks on. The screen reader thus either needs the coordinates of the pointer to determine what widget is at these coordinates, or hover feedback from the widget itself.

### Touchscreen review

User would use a touchscreen in review mode: while moving the finger around the screen, the screen reader says what the finger is on, and only double-taps makes an actual pointer click, as well as other kinds of gestures.

### Braille typing

Some Braille output devices have braille keys, numbered from dot 1 to dot 8. One would for instance type dot 1 to type "a", which is sent by the device to the computer as "a" (not as dot1), which needs to be interpreted as such by the application. Pressing dot 1 and dot 2 at the same time produces "b", which is sent as such by the device, and so one.

Some people can not afford a Braille output device with such keys, and would use the keyboard to type Braille, using keys 'a', 's', 'd', 'f', 'j', 'k', 'l', ';' in a chord. For instance, the 'f' keyboard key is dot 1, and thus typing it alone produces "a". The 'd' keyboard key is dot 2, and thus typing both 'f' and 'd' at the same time produces "b".

Braille contains abreviations. For instance, dot1 ("a") followed by dot1+dot2 ("b") is a contraction for "about". Typing dot1 alone then dot1 and dot2 together, then a word separator character, should expand the contraction to produce "about".

We want the screen reader to be able to provide feedback (optionally "a" and "b", and always "about")

### Global positioning

The user uses e.g. a touchpad as a global positioning device within a virtual field, while another device provides tactile feedback of the virtual field. For instance, allows to get feedback on the frames of the windows of the desktop.

### Touchpad gestures

It should be possible to make touchpad gestures act as key presses (e.g. arrows)

### To be continued...

---

# Examples of ways to achieve them, not necessarily what we can afford in the end

### Mouse event injection

Orca needs this for clicking in flat review mode

See [[https://bugzilla.gnome.org/show_bug.cgi?id=709999]]

### Absolute mouse coordinates event

Orca needs this for flat review

See [[https://bugzilla.gnome.org/show_bug.cgi?id=710012]]

### Key injection

We need to be able to inject both untranslated key presses and translated keypresses, as some specific devices or handling happen to provide both of them.

* keycode injection
 * Available in Xorg through XTest
* keysym injection
 * Not available in Xorg, have to backtranslate.
 * Could be done by adding EV_KEYSYM and EV_UNICODE to evdev layer.

Wayland: this is completely missing apparently?

A bridge for dogtail was implemented on [[https://gitlab.gnome.org/ofourdan/gnome-ponytail-daemon]] but this is more of a hack

### input stealing

We need to be able to steal input event, for instance:

* Orca wants to eat all presses/releases of its "orca key" (insert or capslock, depending on the configuration), to be able to use it for its own shortcuts
* Orca also wants to eat the shortcuts it uses for navigation etc.
* feedback applications want to eat all mouse events from a given touchpad, getting absolute coordinates from it, to use it as a positioning device.

### PC braille keyboard

* Without contractions, available in Xorg as the brai xkb layout
* With contractions, ibus module available: [[https://gitlab.com/smc/ibus-braille]]
